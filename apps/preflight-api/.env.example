# Backend environment
DATABASE_URL=postgresql://preflight:dev_password@localhost:5433/preflight_dev
CORS_ORIGINS=http://localhost:3000,http://localhost:3002
DEBUG=true

# Database Connection Pool
DB_POOL_SIZE=5          # Base number of connections
DB_MAX_OVERFLOW=10      # Max additional connections under load
DB_POOL_TIMEOUT=30      # Seconds to wait for connection
DB_POOL_RECYCLE=1800    # Recycle connections after 30 minutes
DB_POOL_PRE_PING=true   # Verify connections before use
DB_ECHO=false           # Log SQL queries (debugging)

# Authentication
AUTH_MODE=stub  # "stub" for development, "jwt" for production
JWT_SECRET=your-secret-key-min-32-characters-long-here
JWT_ALGORITHM=HS256
JWT_ISSUER=oceanheart.ai
ALLOW_STUB_TOKENS=false  # Set to true to allow stub tokens in JWT mode (testing only)

# Redis (required for production rate limiting)
REDIS_URL=redis://localhost:6379/0

# LLM Service Configuration
LLM_PROVIDER=openai  # openai or anthropic

# OpenAI Configuration
OPENAI_API_KEY=sk-...
OPENAI_ORGANIZATION=  # Optional
OPENAI_DEFAULT_MODEL=gpt-4-turbo

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_DEFAULT_MODEL=claude-3-5-sonnet-20241022

# LLM Request Settings
LLM_REQUEST_TIMEOUT=45
LLM_MAX_RETRIES=3
LLM_DEFAULT_TEMPERATURE=0.7
LLM_DEFAULT_MAX_TOKENS=150

# Cost Monitoring
LLM_MONTHLY_BUDGET_USD=100.0
LLM_COST_ALERT_THRESHOLD=0.8
